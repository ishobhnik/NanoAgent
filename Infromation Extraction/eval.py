import pandas as pd
from seqeval.metrics import classification_report

file = "FINER.parquet"

data = pd.read_parquet(file)

data.info()

from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen2.5-1.5B"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    dtype="auto",
    device_map="auto"
)
prompts = data['query']
labels = data['label']
pred = []
id = data['id']
answer = data['answer']
token = data['token']
def align_labels_with_subparts(true_tokens, pred_tokens, pred_labels):
    """
    Aligns predicted labels (from merged tokens) to the original true tokens,
    inserting 'O' labels for tokens that were missed or are part of a merge.

    Args:
        true_tokens (list): The ground truth tokens (e.g., ['$', '1.5', 'million']).
        pred_tokens (list): The tokens generated by the LLM (e.g., ['$1.5 million']).
        pred_labels (list): The labels generated by the LLM corresponding to pred_tokens.

    Returns:
        list: The aligned list of labels, same length as true_tokens.
    """
    if len(pred_tokens) != len(pred_labels):
        print("Warning: Predicted tokens and labels lists must be of equal length.")
        return ['O'] * len(true_tokens) 

    aligned_labels = []
    pred_idx = 0       
   
    working_pred_tokens = list(pred_tokens)

    for true_token in true_tokens:
       
        if pred_idx >= len(working_pred_tokens):
            aligned_labels.append("O")
            continue

        current_pred_token = working_pred_tokens[pred_idx]
        current_pred_label = pred_labels[pred_idx]
       
        if true_token == current_pred_token:
            aligned_labels.append(current_pred_label)
            pred_idx += 1
           
        elif current_pred_token.startswith(true_token): 
            aligned_labels.append(current_pred_label)
            remaining_part = current_pred_token[len(true_token):].lstrip()
           
            if not remaining_part:
                pred_idx += 1
            else:
                working_pred_tokens[pred_idx] = remaining_part
               
        else:
            aligned_labels.append("O")
           
    if len(aligned_labels) != len(true_tokens):
        print(f"FATAL: Alignment function failed. Expected {len(true_tokens)}, got {len(aligned_labels)}")
        return ['O'] * len(true_tokens)

    return aligned_labels
for i in range (len(prompts)):
    prompt = prompts[i]
    label = labels[i]
    result = answer[i]
    tokens = token[i]
    messages = [{"role": "user", "content": prompt}]

    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
        enable_thinking=True
    )
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

    generate_ids = model.generate(
        **model_inputs,
        max_new_tokens=32768
    )
    output_ids = generate_ids[0][len(model_inputs.input_ids[0]):].tolist()
    try:
        index = len(output_ids) - output_ids[::-1].index(151668)
    except ValueError:
        index = 0

    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip("\n")
    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip("\n")
    print("thinking content:", thinking_content)
    print("content:", content)
    pred_tokens = []
    pred_labels = []
    for line in content.split("\n"):
        if ":" in line:
            token, label = line.split(":")
            pred_tokens.append(token)
            pred_labels.append(label.strip())
    pred = []
    pred.append(pred_labels)
    print(pred_labels, pred_tokens)

    new = align_labels_with_subparts(tokens,pred_tokens,pred_labels)

    entityf1 = []
    print(list(labels[0]), new)
    report = classification_report([list(labels[0])], [list(new)], output_dict=True)
    print(report)
    entityf1.append(report['macro avg']['f1-score'])
    print("Entity F1 scores:", entityf1)
